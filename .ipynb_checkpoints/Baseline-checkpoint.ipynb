{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f51bc6-b653-4a9a-8b42-6d8c3ce9deab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"./sentiment140.py\", name=\"sentiment140\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e9703ba-ed37-4139-877d-1f69d11df8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-125m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL_1\n",
      "0.45\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, OPTForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "num_labels = 2\n",
    "model = OPTForSequenceClassification.from_pretrained(\"facebook/opt-125m\", num_labels=num_labels)\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is sweet\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "print(model.config.id2label.get(predicted_class_id, \"Unknown\"))\n",
    "\n",
    "labels = torch.tensor([1])\n",
    "loss = model(**inputs, labels=labels).loss\n",
    "print(round(loss.item(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "056f2fcc-3083-471b-a1d2-c79516c9c9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-125m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 498/498 [00:00<00:00, 10030.22 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, OPTForSequenceClassification\n",
    "\n",
    "dataset = load_dataset(\"./sentiment140.py\", name=\"sentiment140\")\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "model_name = \"facebook/opt-125m\"\n",
    "num_labels = 2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = OPTForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "model.eval()\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e88c3ff4-d26c-4c19-b23b-b56ac8d0ce33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3353\n",
      "Total Inference Time: 12.68 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "total_samples = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"sentiment\"]\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        correct_predictions += (predictions == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "end_time = time.time()\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Total Inference Time: {inference_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc22b20-22eb-4d6e-9100-a42ad543d4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
